{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# SCALE Multigroup Cross Section Reader\n\nThis example demonstrates how to read SCALE multigroup cross section libraries. This functionality relies on AMPX modules\nfor creating text dumps of COVERX formatted libraries. More details are given here: `mg_reader.inp`. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A Disclaimer\nThe COVERX formatted cross section library referenced in this example ``dummy_56_v7.1`` was created with AMPX using ExSite\nand publicly available cross section data from [ENDF VII.1](https://www.nndc.bnl.gov/endf-b7.1/download.html).\nThis library is **NOT** intended for use in simulations, and only contains a small subset of nuclides and reactions. This\nlibrary is included purely for demonstration purposes, and when using functionality in this package that requires nuclear\ndata, please use the provided SCALE libraries.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reading Multigroup Cross Sections\nThe following code snippet demonstrates how to read a SCALE multigroup cross section library. The function \n:func:`tsunami_ip_utils.xs.read_multigroup_xs` is used to read COVER formatted SCALE cross section libraries, and takes\na :class:`pathlib.Path` object to the multigroup library, and a dictionary of nuclide-reaction pairs to read. The function\nreturns a nested dictionary of :class:`numpy.ndarray` objects, where the outer dictionary keys are nuclides, and the inner\ndictionary keys are reactions. The values are the multigroup cross sections for the corresponding nuclide-reaction pair. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from tsunami_ip_utils.xs import read_multigroup_xs\nfrom paths import EXAMPLES\n\nnuclide_reaction_dict = {'92235': ['1', '18'], '5011': ['1', '27'], '94239': ['1', '18']}\nmultigroup_library_path = EXAMPLES / 'data' / 'dummy_56_v7.1'\nout = read_multigroup_xs(multigroup_library_path, nuclide_reaction_dict)\nprint(len(out['92235']['1']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function is parallel, and reads cross section libraries on multiple cores, which can be useful for large libraries.\nThis function isn't the most user-friendly, and requires the user to input a nuclide_reaction_dict in terms of nuclide\nZAID and reaction MT numbers, but it is primarily used by the :mod:`tsunami_ip_utils.perturbations` module for\nreading cross sections for perturbation calculations.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Caching a Multigroup Cross Section Library\nIf working with python-based applications that deal with SCALE multigroup cross section data, it may be useful to cache the\ncross section libary in a convenient format for reading into python, like a ``.pkl`` file. To avoid having to manually supply\nthe list of all nuclides and reactions in the multigroup library, the :func:`tsunami_ip_utils.xs.read_multigroup_xs` function\ncan be run with the ``return_available_nuclide_reactions`` flag set to ``True``. This will return a dictionary of all nuclides\nand reactions in the library, which can then be used to read the library and cache it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "out, available_nuclide_reactions = read_multigroup_xs(\n    multigroup_library_path, \n    nuclide_reaction_dict, \n    return_available_nuclide_reactions=True\n)\nprint(available_nuclide_reactions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The list of all available nuclide reactions can then be supplied to the function to read the entire library.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "out = read_multigroup_xs(multigroup_library_path, available_nuclide_reactions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the cross sections can be easily cached\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pickle\n\nwith open(EXAMPLES / 'data' / 'dummy_56_v7.1.pkl', 'wb') as f:\n    pickle.dump(out, f)\n\n# Now compare the dump to the gold standard\nimport filecmp\n\nassert filecmp.cmp(EXAMPLES / 'data' / 'dummy_56_v7.1.pkl', EXAMPLES / 'gold' / 'dummy_56_v7.1.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A Future Improvement\nIt is unfortunate that to cache a cross section library, the library must be read twice (the most consuming part is making\nthe text dump again). This is a limitation of the current implementation, and may be improved in the future. To avoid this,\nthe text dump just needs to be saved so that it can be read by the second function call. This could all be implemented by\nadding an additional flag to the :func:`tsunami_ip_utils.xs.read_multigroup_xs` that does this under the hood.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}